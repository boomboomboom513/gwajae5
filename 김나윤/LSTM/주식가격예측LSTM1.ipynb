{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/github/teddylee777/machine-learning/blob/master/04-TensorFlow2.0/01-%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90-%EC%A3%BC%EA%B0%80%EC%98%88%EC%B8%A1/02-LSTM-stock-forecasting-with-LSTM-financedatareader.ipynb#scrollTo=qnaiLGuDbiJe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://woochan-autobiography.tistory.com/871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('삼성바이오로직스 주식 데이터.csv',encoding='cp949', parse_dates = [\"날짜\"])\n",
    "data1 = pd.read_csv('삼성바이오로직스 주식 데이터(투자주체별).csv',encoding='cp949', parse_dates = [\"날짜\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249 entries, 0 to 248\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   종목코드    249 non-null    object        \n",
      " 1   종목명     249 non-null    object        \n",
      " 2   날짜      249 non-null    datetime64[ns]\n",
      " 3   개인      249 non-null    int64         \n",
      " 4   외국인     249 non-null    int64         \n",
      " 5   기관계     249 non-null    int64         \n",
      " 6   금융투자    249 non-null    int64         \n",
      " 7   보험      249 non-null    int64         \n",
      " 8   투신      249 non-null    int64         \n",
      " 9   은행      249 non-null    int64         \n",
      " 10  기타금융    249 non-null    int64         \n",
      " 11  연기금     249 non-null    int64         \n",
      " 12  기타법인    249 non-null    int64         \n",
      " 13  기타외인    249 non-null    int64         \n",
      " 14  사모펀드    249 non-null    int64         \n",
      "dtypes: datetime64[ns](1), int64(12), object(2)\n",
      "memory usage: 29.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['종목코드', '종목명', '날짜', '시간', '시가', '고가', '저가', '종가', '거래량', '거래대금',\n",
       "        '누적체결매도수량', '누적체결매수수량'],\n",
       "       dtype='object'),\n",
       " Index(['종목코드', '종목명', '날짜', '개인', '외국인', '기관계', '금융투자', '보험', '투신', '은행',\n",
       "        '기타금융', '연기금', '기타법인', '기타외인', '사모펀드'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns, data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('종목코드', axis=1, inplace=True) \n",
    "data.drop('종목명', axis=1, inplace=True) \n",
    "data1.drop('종목코드', axis=1, inplace=True) \n",
    "data1.drop('종목명', axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data = pd.merge(data, data1)\n",
    "m_data.drop('누적체결매도수량', axis=1, inplace=True)\n",
    "m_data.drop('누적체결매수수량', axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "투자주체별 합치고 종가 삭제하고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 - 날짜형으로 변경\n",
    "m_data['날짜'] = pd.to_datetime(data['날짜'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data['Year'] = m_data['날짜'].dt.year\n",
    "m_data['Month'] = m_data['날짜'].dt.month\n",
    "m_data['Day'] = m_data['날짜'].dt.day\n",
    "\n",
    "#m_data.drop('날짜', axis = 1, inplace=True)\n",
    "m_data['변화량'] = m_data['종가'] - m_data['시가']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['날짜', '시간', '시가', '고가', '저가', '종가', '거래량', '거래대금', '개인', '외국인', '기관계',\n",
       "       '금융투자', '보험', '투신', '은행', '기타금융', '연기금', '기타법인', '기타외인', '사모펀드', 'Year',\n",
       "       'Month', 'Day', '변화량'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fi = m_data.drop(columns = ['시가', '고가', '저가', '종가', '거래량', '거래대금', '개인', '외국인', '기관계',\n",
    "       '금융투자', '보험', '투신', '은행', '기타금융', '연기금', '기타법인', '기타외인', '사모펀드', ], inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.to_csv('삼성바이오로직스_변화량.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# 스케일을 적용할 column을 정의합니다.\n",
    "scale_cols = ['시간', '시가', '고가', '저가', '종가', '거래량', '거래대금',\n",
    "       '개인', '외국인', '기관계', '금융투자', '보험', '투신', '은행', '기타금융', '연기금', '기타법인',\n",
    "       '기타외인', '사모펀드', 'Year', 'Month', 'Day']\n",
    "# 스케일 후 columns\n",
    "scaled = scaler.fit_transform(m_data[scale_cols])\n",
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(scaled, columns=scale_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train/test 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.drop('종가', 1), df['종가'], test_size=0.2, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시퀀스 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle):\n",
    "    series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1000)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[-1]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터\n",
    "WINDOW_SIZE=20\n",
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trian_data는 학습용 데이터셋, test_data는 검증용 데이터셋 입니다.\n",
    "train_data = windowed_dataset(y_train, WINDOW_SIZE, BATCH_SIZE, True)\n",
    "test_data = windowed_dataset(y_test, WINDOW_SIZE, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래의 코드로 데이터셋의 구성을 확인해 볼 수 있습니다.\n",
    "# X: (batch_size, window_size, feature)\n",
    "# Y: (batch_size, feature)\n",
    "for data in train_data.take(1):\n",
    "    print(f'데이터셋(X) 구성(batch_size, window_size, feature갯수): {data[0].shape}')\n",
    "    print(f'데이터셋(Y) 구성(batch_size, window_size, feature갯수): {data[1].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, Lambda\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    # 1차원 feature map 생성\n",
    "    Conv1D(filters=32, kernel_size=5,\n",
    "           padding=\"causal\",\n",
    "           activation=\"relu\",\n",
    "           input_shape=[WINDOW_SIZE, 1]),\n",
    "    # LSTM\n",
    "    LSTM(16, activation='tanh'),\n",
    "    Dense(16, activation=\"relu\"),\n",
    "    Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence 학습에 비교적 좋은 퍼포먼스를 내는 Huber()를 사용합니다.\n",
    "loss = Huber()\n",
    "optimizer = Adam(0.0005)\n",
    "model.compile(loss=Huber(), optimizer=optimizer, metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earlystopping은 10번 epoch통안 val_loss 개선이 없다면 학습을 멈춥니다.\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "# val_loss 기준 체크포인터도 생성합니다.\n",
    "filename = os.path.join('tmp', 'ckeckpointer.ckpt')\n",
    "checkpoint = ModelCheckpoint(filename, \n",
    "                             save_weights_only=True, \n",
    "                             save_best_only=True, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data, \n",
    "                    validation_data=(test_data), \n",
    "                    epochs=50, \n",
    "                    callbacks=[checkpoint, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "plt.plot(np.asarray(y_test)[20:], label='actual')\n",
    "plt.plot(pred, label='prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-dev-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
