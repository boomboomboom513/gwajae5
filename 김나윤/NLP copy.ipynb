{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import konlpy\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Kkma\n",
    "import numpy as np\n",
    "okt = Okt()\n",
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    with open('../김나윤/뉴스/셀트리온_20210401-20230701.csv', encoding='ANSI') as file:\n",
    "        news_data = pd.read_csv(file)\n",
    "except UnicodeDecodeError:\n",
    "    with open('../김나윤/뉴스/셀트리온_20210401-20230701.csv', encoding='utf-8', errors='replace') as file:\n",
    "        news_data = pd.read_csv(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = news_data[['키워드']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data['키워드'] = news_data['키워드'].replace(',', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# regex = r'[^\\w\\s]'\n",
    "# # text 열의 모든 값을 대상으로 정규표현식을 적용하여 특수문자를 제거\n",
    "# news_data['본문'] = news_data['본문'].apply(lambda x: re.sub(regex, '', str(x)))\n",
    "# news_data['제목'] = news_data['제목'].apply(lambda x: re.sub(regex, '', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install konlpy\n",
    "from konlpy.tag import Kkma        \n",
    "kkma = Kkma()\n",
    "from konlpy.tag import Hannanum    \n",
    "hannanum = Hannanum()\n",
    "from konlpy.tag import Okt         \n",
    "t = Okt() \n",
    "from konlpy.tag import *\n",
    "import nltk\n",
    "import pickle\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8390it [03:36, 38.76it/s]\n"
     ]
    }
   ],
   "source": [
    "pos_tag = []\n",
    "\n",
    "# news_data 데이터프레임의 각 행에 대해 반복\n",
    "for _, row in tqdm(news_data.iterrows()):\n",
    "    # 현재 행의 content 값을 news_text 변수에 할당\n",
    "    news_text = row['키워드']\n",
    "    # PosTagging\n",
    "    tokens_ko = t.pos(news_text)\n",
    "    pos_tag.append(tokens_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('확대', 'Noun'), ('제품', 'Noun'), ('영역', 'Noun'), ('셀트리온', 'Noun'), ('시', 'Modifier'), ('밀러', 'Noun'), ('안과', 'Noun'), ('질환', 'Noun'), ('치료', 'Noun'), ('제', 'Noun'), ('시', 'Modifier'), ('밀러', 'Noun'), ('품목', 'Noun'), ('허가', 'Noun'), ('신청', 'Noun'), ('CT', 'Alpha'), ('-', 'Punctuation'), ('P', 'Alpha'), ('아', 'Exclamation'), ('일', 'Modifier'), ('리아', 'Noun'), ('바이오', 'Noun'), ('밀러', 'Noun'), ('CT', 'Alpha'), ('-', 'Punctuation'), ('P', 'Alpha'), ('품목', 'Noun'), ('허가', 'Noun'), ('신청', 'Noun'), ('추진', 'Noun'), ('현지', 'Noun'), ('성인', 'Noun'), ('적응', 'Noun'), ('증', 'Noun'), ('품목', 'Noun'), ('허가', 'Noun'), ('매출', 'Noun'), ('아', 'Exclamation'), ('일', 'Modifier'), ('리아', 'Noun'), ('글로벌', 'Noun'), ('12조', 'Number'), ('자가면역질환', 'Noun'), ('항암제', 'Noun'), ('확대', 'Noun'), ('안과', 'Noun'), ('질환', 'Noun'), ('영역', 'Noun'), ('셀트리온', 'Noun'), ('29일', 'Number'), ('현지', 'Noun'), ('시간', 'Noun'), ('아', 'Exclamation'), ('일', 'Modifier'), ('리아', 'Noun'), ('안과', 'Noun'), ('질환', 'Noun'), ('치료', 'Noun'), ('제', 'Noun'), ('EYLEA', 'Alpha'), ('애플', 'Noun'), ('리버', 'Noun'), ('셉트', 'Noun'), ('바이오', 'Noun'), ('밀러', 'Noun'), ('CT', 'Alpha'), ('-', 'Punctuation'), ('P', 'Alpha'), ('품목', 'Noun'), ('허가', 'Noun'), ('미국', 'Noun'), ('식품', 'Noun'), ('의', 'Noun'), ('약국', 'Noun'), ('FDA', 'Alpha'), ('신청', 'Noun'), ('30일', 'Number'), ('CT', 'Alpha'), ('-', 'Punctuation'), ('P', 'Alpha'), ('셀트리온', 'Noun'), ('제품', 'Noun'), ('포트폴리오', 'Noun'), ('확장', 'Noun'), ('바이오', 'Noun'), ('시', 'Modifier'), ('밀러', 'Noun'), ('오', 'Modifier'), ('리지', 'Noun'), ('널', 'Noun'), ('제품', 'Noun'), ('아', 'Exclamation'), ('일', 'Modifier'), ('리아', 'Noun'), ('12조', 'Number'), ('규모', 'Noun'), ('글로벌', 'Noun'), ('시장', 'Noun'), ('형성', 'Noun'), ('독점', 'Noun'), ('권', 'Suffix'), ('아', 'Exclamation'), ('일', 'Modifier'), ('리아', 'Noun'), ('미국', 'Noun'), ('독점', 'Noun'), ('내년', 'Noun'), ('유럽', 'Noun'), ('물질', 'Noun'), ('특허', 'Noun'), ('만료', 'Noun'), ('예정', 'Noun'), ('특허', 'Noun'), ('종료', 'Noun'), ('셀트리온', 'Noun'), ('글로벌', 'Noun'), ('국가', 'Noun'), ('순차', 'Noun'), ('적', 'Suffix'), ('허가', 'Noun'), ('신청', 'Noun'), ('계획', 'Noun'), ('미국', 'Noun'), ('신청', 'Noun'), ('유럽', 'Noun'), ('허가', 'Noun'), ('준비', 'Noun'), ('셀트리온', 'Noun'), ('품목', 'Noun'), ('허가', 'Noun'), ('신청', 'Noun'), ('글로벌', 'Noun'), ('임', 'Noun'), ('상', 'Suffix'), ('결과', 'Noun'), ('바탕', 'Noun'), ('습성', 'Noun'), ('황반', 'Noun'), ('변성', 'Noun'), ('wAMD', 'Alpha'), ('당뇨병', 'Noun'), ('황반', 'Noun'), ('부종', 'Noun'), ('DME', 'Alpha'), ('소아', 'Noun'), ('적응', 'Noun'), ('증', 'Noun'), ('제외', 'Noun'), ('아', 'Exclamation'), ('일', 'Modifier'), ('리아', 'Noun'), ('미국', 'Noun'), ('적응', 'Noun'), ('증', 'Noun'), ('3', 'Number'), ('상', 'Noun'), ('임', 'Noun'), ('상', 'Suffix'), ('체코', 'Noun'), ('헝가리', 'Noun'), ('폴란드', 'Noun'), ('스페인', 'Noun'), ('국가', 'Noun'), ('당뇨병', 'Noun'), ('황반', 'Noun'), ('부종', 'Noun'), ('환자', 'Noun'), ('대상', 'Noun'), ('진행', 'Noun'), ('동등', 'Noun'), ('성', 'Suffix'), ('오', 'Modifier'), ('리지', 'Noun'), ('널', 'Noun'), ('대비', 'Noun'), ('동등', 'Noun'), ('유사성', 'Noun'), ('확인', 'Noun'), ('미국', 'Noun'), ('리제', 'Noun'), ('네', 'Determiner'), ('론', 'Noun'), ('Regeneron', 'Alpha'), ('아', 'Exclamation'), ('일', 'Modifier'), ('리아', 'Noun'), ('기준', 'Noun'), ('글로벌', 'Noun'), ('매출', 'Noun'), ('달러', 'Noun'), ('12조', 'Number'), ('기록', 'Noun'), ('치료', 'Noun'), ('제', 'Noun'), ('블록버스터', 'Noun'), ('안과', 'Noun'), ('질환', 'Noun'), ('셀트리온', 'Noun'), ('관계자', 'Noun'), ('CT', 'Alpha'), ('-', 'Punctuation'), ('P', 'Alpha'), ('임', 'Noun'), ('상', 'Suffix'), ('확인', 'Noun'), ('오', 'Modifier'), ('리지', 'Noun'), ('널', 'Noun'), ('의약품', 'Noun'), ('대비', 'Noun'), ('동등', 'Noun'), ('유사', 'Noun'), ('바탕', 'Noun'), ('미국', 'Noun'), ('FDA', 'Alpha'), ('품목', 'Noun'), ('허가', 'Noun'), ('신청', 'Noun'), ('미국', 'Noun'), ('시작', 'Noun'), ('유럽', 'Noun'), ('국가', 'Noun'), ('순차', 'Noun'), ('적', 'Suffix'), ('허가', 'Noun'), ('신청', 'Noun'), ('안과', 'Noun'), ('질환', 'Noun'), ('영역', 'Noun'), ('바이오', 'Noun'), ('밀러', 'Noun'), ('포트폴리오', 'Noun'), ('확장', 'Noun'), ('셀트리온', 'Noun'), ('CT', 'Alpha'), ('-', 'Punctuation'), ('P', 'Alpha'), ('포함', 'Noun'), ('최대', 'Noun'), ('바이오', 'Noun'), ('시', 'Modifier'), ('밀러', 'Noun'), ('제품', 'Noun'), ('신청', 'Noun'), ('글로벌', 'Noun'), ('허가', 'Noun'), ('계획', 'Noun'), ('천식', 'Noun'), ('알레르기', 'Noun'), ('만성', 'Noun'), ('특발', 'Noun'), ('두드러기', 'Noun'), ('치료', 'Noun'), ('제', 'Noun'), ('졸레어', 'Noun'), ('XOLAIR', 'Alpha'), ('오', 'Modifier'), ('말리', 'Noun'), ('주', 'Modifier'), ('맙', 'Noun'), ('바이오', 'Noun'), ('시', 'Modifier'), ('밀러', 'Noun'), ('CT', 'Alpha'), ('-', 'Punctuation'), ('P', 'Alpha'), ('품목', 'Noun'), ('허가', 'Noun'), ('식품', 'Noun'), ('의', 'Josa'), ('약국', 'Noun'), ('안전', 'Noun'), ('처', 'Noun'), ('식약처', 'Noun'), ('접수', 'Noun')]\n"
     ]
    }
   ],
   "source": [
    "#첫번째 행의 Pos Tagging\n",
    "print(pos_tag[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['확대', ',', '제품', ',', '영역', ',', '셀트리온', ',', '시', '밀러', ',', '안과', ',', '질환', ',', '치료', '제', ',', '시', '밀러', ',', '품목', ',', '허가', ',', '신청', ',', 'CT', '-', 'P', ',', '아', '일', '리아', ',', '바이오', ',', '밀러', ',', 'CT', '-', 'P', ',', '품목', ',', '허가', ',', '신청', ',', '추진', ',', '현지', ',', '성인', ',', '적응', '증', ',', '품목', ',', '허가', ',', '매출', ',', '아', '일', '리아', ',', '글로벌', ',', '12조', ',', '자가면역질환', ',', '항암제', ',', '확대', ',', '안과', ',', '질환', ',', '영역', ',', '셀트리온', ',', '29일', ',', '현지', '시간', ',', '아', '일', '리아', ',', '안과', ',', '질환', ',', '치료', '제', ',', 'EYLEA', ',', '애플', '리버', '셉트', ',', '바이오', ',', '밀러', ',', 'CT', '-', 'P', ',', '품목', '허가', ',', '미국', ',', '식품', ',', '의', '약국', ',', 'FDA', ',', '신청', ',', '30일', ',', 'CT', '-', 'P', ',', '셀트리온', ',', '제품', ',', '포트폴리오', ',', '확장', ',', '바이오', '시', '밀러', ',', '오', '리지', '널', ',', '제품', ',', '아', '일', '리아', ',', '12조', ',', '규모', ',', '글로벌', ',', '시장', ',', '형성', ',', '독점', ',', '아', '일', '리아', ',', '미국', ',', '독점', ',', '내년', ',', '유럽', ',', '물질', ',', '특허', ',', '만료', ',', '예정', ',', '특허', ',', '종료', ',', '셀트리온', ',', '글로벌', ',', '국가', ',', '순차', ',', '허가', ',', '신청', ',', '계획', ',', '미국', ',', '신청', ',', '유럽', ',', '허가', ',', '준비', ',', '셀트리온', ',', '품목', ',', '허가', ',', '신청', ',', '글로벌', ',', '임', ',', '결과', ',', '바탕', ',', '습성', ',', '황반', ',', '변성', ',', 'wAMD', ',', '당뇨병', ',', '황반', ',', '부종', ',', 'DME', ',', '소아', ',', '적응', '증', ',', '제외', ',', '아', '일', '리아', ',', '미국', ',', '적응', '증', ',', '3', '상', ',', '임', ',', '체코', ',', '헝가리', ',', '폴란드', ',', '스페인', ',', '국가', ',', '당뇨병', ',', '황반', ',', '부종', ',', '환자', ',', '대상', ',', '진행', ',', '동등', ',', '오', '리지', '널', ',', '대비', ',', '동등', ',', '유사성', ',', '확인', ',', '미국', ',', '리제', '네', '론', ',', 'Regeneron', ',', '아', '일', '리아', ',', '기준', ',', '글로벌', ',', '매출', ',', '달러', ',', '12조', ',', '기록', ',', '치료', '제', ',', '블록버스터', ',', '안과', ',', '질환', ',', '셀트리온', ',', '관계자', ',', 'CT', '-', 'P', ',', '임', ',', '확인', ',', '오', '리지', '널', ',', '의약품', ',', '대비', ',', '동등', ',', '유사', ',', '바탕', ',', '미국', ',', 'FDA', ',', '품목', ',', '허가', ',', '신청', ',', '미국', ',', '시작', ',', '유럽', ',', '국가', ',', '순차', ',', '허가', ',', '신청', ',', '안과', ',', '질환', ',', '영역', ',', '바이오', ',', '밀러', ',', '포트폴리오', ',', '확장', ',', '셀트리온', ',', 'CT', '-', 'P', ',', '포함', ',', '최대', ',', '바이오', ',', '시', '밀러', ',', '제품', ',', '신청', ',', '글로벌', ',', '허가', ',', '계획', ',', '천식', ',', '알레르기', ',', '만성', ',', '특발', ',', '두드러기', ',', '치료', '제', ',', '졸레어', ',', 'XOLAIR', ',', '오', '말리', '주', '맙', ',', '바이오', '시', '밀러', ',', 'CT', '-', 'P', ',', '품목', '허가', ',', '식품', '약국', '안전', '처', ',', '식약처', ',', '접수']\n"
     ]
    }
   ],
   "source": [
    "normalization_li = []\n",
    "for pos in pos_tag: \n",
    "    in_li = []\n",
    "    for ele in pos:\n",
    "        #품사가 조사, 접속사이면 continue\n",
    "        if ele[1] in ['Josa','Suffix']:\n",
    "            continue\n",
    "        in_li.append(ele[0])\n",
    "    normalization_li.append(in_li)\n",
    "print(normalization_li[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../김나윤/data/stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.readlines()\n",
    "stopwords = [x.replace('\\n','') for x in stopwords] # stopword 파일의 줄바꿈 문자 제거\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['확대', ',', '제품', ',', '영역', ',', '셀트리온', ',', '시', '밀러', ',', '안과', ',', '질환', ',', '치료', ',', '시', '밀러', ',', '품목', ',', '허가', ',', '신청', ',', 'CT', '-', 'P', ',', '리아', ',', '바이오', ',', '밀러', ',', 'CT', '-', 'P', ',', '품목', ',', '허가', ',', '신청', ',', '추진', ',', '현지', ',', '성인', ',', '적응', '증', ',', '품목', ',', '허가', ',', '매출', ',', '리아', ',', '글로벌', ',', '12조', ',', '자가면역질환', ',', '항암제', ',', '확대', ',', '안과', ',', '질환', ',', '영역', ',', '셀트리온', ',', '29일', ',', '현지', ',', '리아', ',', '안과', ',', '질환', ',', '치료', ',', 'EYLEA', ',', '애플', '리버', '셉트', ',', '바이오', ',', '밀러', ',', 'CT', '-', 'P', ',', '품목', '허가', ',', '미국', ',', '식품', ',', '약국', ',', 'FDA', ',', '신청', ',', '30일', ',', 'CT', '-', 'P', ',', '셀트리온', ',', '제품', ',', '포트폴리오', ',', '확장', ',', '바이오', '시', '밀러', ',', '리지', '널', ',', '제품', ',', '리아', ',', '12조', ',', '규모', ',', '글로벌', ',', '시장', ',', '형성', ',', '독점', ',', '리아', ',', '미국', ',', '독점', ',', '내년', ',', '유럽', ',', '물질', ',', '특허', ',', '만료', ',', '예정', ',', '특허', ',', '종료', ',', '셀트리온', ',', '글로벌', ',', '국가', ',', '순차', ',', '허가', ',', '신청', ',', '계획', ',', '미국', ',', '신청', ',', '유럽', ',', '허가', ',', '준비', ',', '셀트리온', ',', '품목', ',', '허가', ',', '신청', ',', '글로벌', ',', '임', ',', '결과', ',', '바탕', ',', '습성', ',', '황반', ',', '변성', ',', 'wAMD', ',', '당뇨병', ',', '황반', ',', '부종', ',', 'DME', ',', '소아', ',', '적응', '증', ',', '제외', ',', '리아', ',', '미국', ',', '적응', '증', ',', '3', '상', ',', '임', ',', '체코', ',', '헝가리', ',', '폴란드', ',', '스페인', ',', '국가', ',', '당뇨병', ',', '황반', ',', '부종', ',', '환자', ',', '대상', ',', '진행', ',', '동등', ',', '리지', '널', ',', '대비', ',', '동등', ',', '유사성', ',', '확인', ',', '미국', ',', '리제', '론', ',', 'Regeneron', ',', '리아', ',', '기준', ',', '글로벌', ',', '매출', ',', '달러', ',', '12조', ',', '기록', ',', '치료', ',', '블록버스터', ',', '안과', ',', '질환', ',', '셀트리온', ',', '관계자', ',', 'CT', '-', 'P', ',', '임', ',', '확인', ',', '리지', '널', ',', '의약품', ',', '대비', ',', '동등', ',', '유사', ',', '바탕', ',', '미국', ',', 'FDA', ',', '품목', ',', '허가', ',', '신청', ',', '미국', ',', '시작', ',', '유럽', ',', '국가', ',', '순차', ',', '허가', ',', '신청', ',', '안과', ',', '질환', ',', '영역', ',', '바이오', ',', '밀러', ',', '포트폴리오', ',', '확장', ',', '셀트리온', ',', 'CT', '-', 'P', ',', '포함', ',', '최대', ',', '바이오', ',', '시', '밀러', ',', '제품', ',', '신청', ',', '글로벌', ',', '허가', ',', '계획', ',', '천식', ',', '알레르기', ',', '만성', ',', '특발', ',', '두드러기', ',', '치료', ',', '졸레어', ',', 'XOLAIR', ',', '말리', '주', '맙', ',', '바이오', '시', '밀러', ',', 'CT', '-', 'P', ',', '품목', '허가', ',', '식품', '약국', '안전', '처', ',', '식약처', ',', '접수']\n"
     ]
    }
   ],
   "source": [
    "tokens = normalization_li\n",
    "token_stop = []\n",
    "for token in tokens:\n",
    "    in_li = []\n",
    "    for tok in token:\n",
    "        if tok not in stopwords:\n",
    "            in_li.append(tok)\n",
    "    token_stop.append(in_li)\n",
    "print(token_stop[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from konlpy.tag import Kkma        ; kkma = Kkma()\n",
    "from konlpy.tag import Hannanum    ; hannanum = Hannanum()\n",
    "from konlpy.tag import Okt         ; t = Okt()     # 구 트위터\n",
    "from konlpy.tag import *\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rc('font', family='NanumGothic')\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_text = ''\n",
    "news_data = preprocess.reset_index(drop=True)\n",
    "for _, row in news_data.iterrows():\n",
    "    news_text += row['키워드']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2181069\n",
      "46249\n",
      "[('셀트리온', 34141), ('바이오', 32515), ('기업', 16563), ('시장', 14600), ('하락', 12758), ('상승', 12366), ('거래', 12149), ('제', 11709), ('코스피', 11663), ('미국', 11595), ('투자', 10706), ('적', 10511), ('지수', 9996), ('종목', 9966), ('이', 9873), ('주가', 9524), ('포인트', 9476), ('들', 9239), ('치료', 8971), ('외국인', 8916)]\n"
     ]
    }
   ],
   "source": [
    "tokens_ko = t.morphs(news_text)\n",
    "ko = nltk.Text(tokens_ko)\n",
    "\n",
    "print(len(ko.tokens))          # 토큰 전체 개수\n",
    "print(len(set(ko.tokens)))     # 토큰 unique 개수\n",
    "print(ko.vocab().most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['바이오','삼성','성','삼','로', '적', '이', '셀트리온']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_ko = [each_word for each_word in tokens_ko\n",
    "           if each_word not in stop_words]\n",
    "\n",
    "\n",
    "ko = nltk.Text(tokens_ko)\n",
    "\n",
    "# 그래프에서 한글 폰트가 깨질 경우 실행\n",
    "# from matplotlib import font_manager, rc\n",
    "# font_name = font_manager.FontProperties(fname='c:/Windows/Fonts/malgun.ttf').get_name()\n",
    "# rc('font', family=font_name)\n",
    "\n",
    "# plt.figure(figsize=(15,6))\n",
    "# ko.plot(50)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8390"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ko.vocab().most_common(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['단어'] = [re.sub('[^A-Za-z0-9가-힣]', '', s) for s in df['단어']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['단어','빈도'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 한거 :  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>단어</th>\n",
       "      <th>빈도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [단어, 빈도]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./셀트리온_단어.csv', index_col=0)\n",
    "check = df[(df['빈도'] == 0) | (df['빈도'] == -1)]\n",
    "print('\\n', '한거 : ' , len(check))\n",
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = pd.DataFrame(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[39m.\u001b[39;49minfo()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'info'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "check.to_csv('긍부정_단어(156).csv', index= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ko.vocab().most_common(num)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-dev-cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
